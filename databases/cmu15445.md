# CMU 15-445 notes

### Lecture 1 - Intro to databases

- computers are powerful because they can perform fast and accurate computations on vast amounts of data.

- databases are software which can organize collections of inter-related data that model some aspect of the real world. How do we implement this?

	- flat file database: store relational data as comma seperated values files.
		- inefficient querying if database is too large (have to search line by line)
		- need to parse data for every query
		- how do we deal with duplicates?
		- how do we deal with different threads using the same db file?
		- how do we deal with machine crashes in the middle of updates?
		- what if we the file gets too big for a single machine and we need to split the db per multiple machines?

- A database management system (DBMS) is software that allows creation, querying, updating and administration of databases and takes care of above concerns and more.

- A _data model_ is an abstraction to describe the data living in a database. A _schema_ defines what a certain collection of data looks like.

- Some example data models: relational, key-value, graph, document/object, array/matrix

#### Relational model
- data is abstractly stored as relations
- this data can be accessed using high-level language and DBMS figures out best execution strategy
- the internal storage implementation of data is up to DBMS (tree, index, hash etc.)
- every real-world data entity has _attributes_ which describes the entity. a _relation_ is a set of entities with certain attributes. a _tuple_ is a set of attribute values (or the domain) in the relation.
- n-ary relation = n-column table; tuple = row in relation
- a relation's _primary key_ attribute (or set of attributes) uniquely identifies a single tuple
- a _foregin key_ is a common attribute between different relations that defines relationships between foreign entities of different cardinalites like:
	- one-to-one
	- one-to-many: note that lecturer admits we can just use an array to store the "many" attribute values in the secondary relation which all have the same foregin key found once in the primary relation.
	- many-to-many
- procedural (relational algebra) and non-procedural/declarative (relational calculus) primitives to access/query data inside relations.
- relational algebra operators: SELECT, PROJECTION, UNION, INTERSECTION, DIFFERENCE, PRODUCT, JOIN. The order of operations in a query can affect performance.
- SQL is a declarative de facto standard query language implemenation for relational models.

#### Object/document model
- examples: mongodb, elastic, couchbase, dynamodb
- embed data hierarchy/relations into a single document
- what if we want to query data in the hierarchy from the bottom up?
- example: if we have something like {ARTIST, [ALBUM1, ALBUM2, ALBUM3]}, it is easy to query all the albums of an artist but what if we want to query artists from albums. We would need to replicate the data but with {ALBUM, [ARTIST1, ARTIS2...]} and store both collections. This is a lot of redudant and duplicate data and any changes need to be propagated everywhere.


#### Vector data model
- examples: pinecone, weaviate, marqo, lancedb
- natively stores vectors (1d arrays)
- nearest-neighbor search used to answer queries (instead of exact lookups) and generates ranked list of items (with rank indicating items which are the best match for query)
- used for semantic search on embeddings generated by ml-trained models (chatgpt)

### Lecture 3 - Database storage

#### Disk-based architecture
- primary storage location of database is non-volatile disk (eg. ssd, hdd, network storage) and manages movement of data between non-volatile and volatile memory (DRAM, caches, registers).
- we assume volatile memory is byte-addressable and non-volatile memory is block-addressable. We want to maximise sequential access of blocks on disk. We are fine with random access of memory in RAM but try to minimise writes to random pages. 
- aside: persistent memory is non-volatile memory with access speed of RAM. eg: some SSDs, Intel Optane.
- System design goals:
	- create illusion that entire database is in memory even if larger than memory available (quite similar to virtual memory)
	- large stalls from writing to disk must be managed carefully to avoid peromfrance degredation
	- maximise sequential access on disk (as mentioned before)
- database files are divided into pages and stored on disk. a buffer pool is maintained in memory for programs to interpret these pages. How does DBMS decide which pages to move in and out of buffer pool?
- Memory-mapped I/O solution: we leave that to OS which uses _mmap_ to store contents of file into address space of program (virtual memory).

	[Are You Sure You Want to Use MMAP in Your Database Management System?](https://www.youtube.com/watch?v=1BRGU_AS25c&ab_channel=CIDRDB) ([paper](https://www.cidrdb.org/cidr2022/papers/p13-crotty.pdf))

	- Problem 1: Page fault stalls if required page is not in memory. Maybe we can just allow multiple threads to access mmap files to hide these stalls? This may work well for read-only threads.
	- Problem 2: What if there are multiple writer threads? How does the OS ensure transaction safety of writes? It doesn't know anything about the database goals and can flush pages out any time.
	- Problem 3: Handling SIGBUS interrupts from invalid page access and we need signal handler throughout system or mechanism to validate pages before access.
	- Problem 4: Performance issues due to [OS data structure contention](https://www.youtube.com/watch?v=DJ5u5HrbcMk&list=PLSE8ODhjZXjbj8BMuIrRcacnQh20hmY9g&index=4&ab_channel=CMUDatabaseGroup) (read comment under video) as the OS needs to schedule thread on-the-fly. Our own disk scheduler, on the other hand, can benefit from having a pre-decided scheduler plan from the declarative SQL query.
	
	There are some solutions to these problems like:
	- _MAP_PRIVATE_: We can solve the transaction safety problem by using OS's copy-on-write feature so that pages modified by program are copied in phyiscal memory before applying the changes and we retain both versions. A write-ahead-log (WAL) is used to record changes and when a transaction commmits, the WAL is flushed to secondary storage and the final version of the COW-tree is persisted. Note that we may eventually end up with a COW-tree double the size of db file if we never shrink the tree which can done using _mremap_.
	- _madvise_: inform the OS of the scheduler plan based on SQL query so it can expect to read certain pages.
	- _mlock_: tell the os which memory ranges cannot be paged out
	- _msync_: tell the os which memory ranges to flush to disk

	Databases which fully use mmap:
	- elastic, monetdb, lmdb (funny story in video), mongodb (but they bought wiredtiger storage engine later)

- Custom storage manager solution: DBMS owns memory management of pages
	- blocks on disk represnted using pages which contaian tuples, metadata, indexes, logs etc. Pages can refere to three types in a DBMS:
		- hardware pages: 4kb in size (largest atomic write size)
		- os page: 4kb
		- db page: 512b - 32kb
	- to idenitfy pages, we use page id to represent offset in some file for a given page size. each page has header metadata describing page contents.
	- How do we manage and organise pages in files on disk?
		- heap file: unordered collection pages with tuples inside pages stored in random order. Easy to find pages if db is a single file (offset = #page * page_size). If multiple files, need metadata to track where pages exist and free space exists: aka page directory.
		- tree file
		- sequential / sorted
		- hashing file
	- How is data organised inside each page? Assume tuples are stored in row-oriented manner.
		- tuple-oriented: how do we store tuples in each page? Flat, linear storage doesn't work can allow for fast indexing but what if tuple postions change? what if all tuples are not fixed size?
			- _Slotted pages_ is the most common page layout scheme which can solve our issues. A slot array points to the starting offsets of individual tuples. Tuples grow bottom-up from page and slots grow top-down.
		
		  How do applications identify tuples from each page? We use Record IDs.
			- Record ID = file_id + page_id + slot_#

		- log-structured
		- index-organized
